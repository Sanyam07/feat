{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 Feat is a feature engineering automation tool that learns data representations for classification and regression. The underlying methods use Pareto optimization and evolutionary computation to search the space of possible transformations.","title":"Introduction"},{"location":"#home","text":"Feat is a feature engineering automation tool that learns data representations for classification and regression. The underlying methods use Pareto optimization and evolutionary computation to search the space of possible transformations.","title":"Home"},{"location":"api_c/","text":"Feat C++ API \u00b6 This is the C++ API for Feat . Click here to return to the main documentation.","title":"Feat C++ API"},{"location":"api_c/#feat-c-api","text":"This is the C++ API for Feat . Click here to return to the main documentation.","title":"Feat C++ API"},{"location":"contributing/","text":"Contributing \u00b6 Please follow the Github flow guidelines for contributing to this project. In general, this is the approach: Fork the repo into your own repository and clone it locally. git clone https://github.com/my_user_name/feat Have an idea for a code change. Checkout a new branch with an appropriate name. git checkout -b my_new_change Make your changes. Commit your changes to the branch. git commit -m \"adds my new change\" Check that your branch has no conflict with Feat\u2019s master branch by merging the master branch from the upstream repo. git remote add upstream https://github.com/lacava/feat git fetch upstream git merge upstream/master Fix any conflicts and commit. git commit -m \"Merges upstream master\" Push the branch to your forked repo. git push origin my_new_change Go to either Github repo and make a new Pull Request for your forked branch. Be sure to reference any relevant issues.","title":"Contribute"},{"location":"contributing/#contributing","text":"Please follow the Github flow guidelines for contributing to this project. In general, this is the approach: Fork the repo into your own repository and clone it locally. git clone https://github.com/my_user_name/feat Have an idea for a code change. Checkout a new branch with an appropriate name. git checkout -b my_new_change Make your changes. Commit your changes to the branch. git commit -m \"adds my new change\" Check that your branch has no conflict with Feat\u2019s master branch by merging the master branch from the upstream repo. git remote add upstream https://github.com/lacava/feat git fetch upstream git merge upstream/master Fix any conflicts and commit. git commit -m \"Merges upstream master\" Push the branch to your forked repo. git push origin my_new_change Go to either Github repo and make a new Pull Request for your forked branch. Be sure to reference any relevant issues.","title":"Contributing"},{"location":"install/","text":"Installing \u00b6 To see our installation process from scratch, check out the Travis install file . Feat depends on the Eigen matrix library for C++ as well as the Shogun ML library. Both come in easy packages that work across platforms. If you need Eigen and Shogun, follow the instructions in Dependencies . Feat uses cmake to build. It uses the typical set of instructions: git clone https://github.com/lacava/feat # clone the repo cd feat # enter the directory ./configure # this runs \"mkdir build; cd build; cmake .. \" ./install # this runs \"make -C build VERBOSE=1 -j8\" Python wrapper \u00b6 The python wrapper is installed using setuptools as follows: cd python python setup.py install Dependencies \u00b6 Eigen \u00b6 Eigen is a header only package. We need Eigen 3 or greater. Debian/Ubuntu \u00b6 On Debian systems, you can grab the package: sudo apt-get install libeigen3-dev You can also download the headers and put them somewhere. Then you just have to tell cmake where they are with the environmental variable EIGEN3_INCLUDE_DIR . Example: # grab Eigen 3.3.4 wget \"http://bitbucket.org/eigen/eigen/get/3.3.4.tar.gz\" tar xzf 3.3.4.tar.gz mkdir eigen-3.3.4 mv eigen-eigen*/* eigen-3.3.4 # set an environmental variable to tell cmake where Eigen is export EIGEN3_INCLUDE_DIR=\"$(pwd)/eigen-3.3.4/\" Shogun \u00b6 You don\u2019t have to compile Shogun, just download the binaries. Their install guide is good. . We\u2019ve listed two of the options here. Anaconda \u00b6 A good option for Anaconda users is the Shogun Anaconda package. If you use conda, you can get what you need by conda install -c conda-forge shogun-cpp If you do this, you need cmake to find Anaconda\u2019s library and include directories. Set these two variables: export SHOGUN_LIB=/home/travis/miniconda/lib/ export SHOGUN_DIR=/home/travis/miniconda/include/ Debian/Ubuntu \u00b6 You can also get the Shogun packages: sudo add-apt-repository ppa:shogun-toolbox/nightly -y sudo apt-get update -y sudo apt-get install -qq --force-yes --no-install-recommends libshogun18 sudo apt-get install -qq --force-yes --no-install-recommends libshogun-dev Running the tests \u00b6 This is totally optional! If you want to run the tests, you need to install Google Test . A useful guide to doing so is available here . Then you can use cmake to build the tests. From the repo root, ./configure tests # builds the test Makefile make -C build tests # compiles the tests ./build/tests # runs the tests","title":"Installation"},{"location":"install/#installing","text":"To see our installation process from scratch, check out the Travis install file . Feat depends on the Eigen matrix library for C++ as well as the Shogun ML library. Both come in easy packages that work across platforms. If you need Eigen and Shogun, follow the instructions in Dependencies . Feat uses cmake to build. It uses the typical set of instructions: git clone https://github.com/lacava/feat # clone the repo cd feat # enter the directory ./configure # this runs \"mkdir build; cd build; cmake .. \" ./install # this runs \"make -C build VERBOSE=1 -j8\"","title":"Installing"},{"location":"install/#python-wrapper","text":"The python wrapper is installed using setuptools as follows: cd python python setup.py install","title":"Python wrapper"},{"location":"install/#dependencies","text":"","title":"Dependencies"},{"location":"install/#eigen","text":"Eigen is a header only package. We need Eigen 3 or greater.","title":"Eigen"},{"location":"install/#debianubuntu","text":"On Debian systems, you can grab the package: sudo apt-get install libeigen3-dev You can also download the headers and put them somewhere. Then you just have to tell cmake where they are with the environmental variable EIGEN3_INCLUDE_DIR . Example: # grab Eigen 3.3.4 wget \"http://bitbucket.org/eigen/eigen/get/3.3.4.tar.gz\" tar xzf 3.3.4.tar.gz mkdir eigen-3.3.4 mv eigen-eigen*/* eigen-3.3.4 # set an environmental variable to tell cmake where Eigen is export EIGEN3_INCLUDE_DIR=\"$(pwd)/eigen-3.3.4/\"","title":"Debian/Ubuntu"},{"location":"install/#shogun","text":"You don\u2019t have to compile Shogun, just download the binaries. Their install guide is good. . We\u2019ve listed two of the options here.","title":"Shogun"},{"location":"install/#anaconda","text":"A good option for Anaconda users is the Shogun Anaconda package. If you use conda, you can get what you need by conda install -c conda-forge shogun-cpp If you do this, you need cmake to find Anaconda\u2019s library and include directories. Set these two variables: export SHOGUN_LIB=/home/travis/miniconda/lib/ export SHOGUN_DIR=/home/travis/miniconda/include/","title":"Anaconda"},{"location":"install/#debianubuntu_1","text":"You can also get the Shogun packages: sudo add-apt-repository ppa:shogun-toolbox/nightly -y sudo apt-get update -y sudo apt-get install -qq --force-yes --no-install-recommends libshogun18 sudo apt-get install -qq --force-yes --no-install-recommends libshogun-dev","title":"Debian/Ubuntu"},{"location":"install/#running-the-tests","text":"This is totally optional! If you want to run the tests, you need to install Google Test . A useful guide to doing so is available here . Then you can use cmake to build the tests. From the repo root, ./configure tests # builds the test Makefile make -C build tests # compiles the tests ./build/tests # runs the tests","title":"Running the tests"},{"location":"api/python/api_py/","text":"feat \u00b6 Feat uses GP to find a data representation that improves the performance of a given ML method.","title":"feat"},{"location":"api/python/api_py/#feat","text":"Feat uses GP to find a data representation that improves the performance of a given ML method.","title":"feat"},{"location":"examples/ex_command_line/","text":"Command line example \u00b6 Feat can be run from the command-line. All of its options are configurable there. After a default build, the feat executable will be in the build directory. From the repo directory, type ./build/feat -h to see options. The first argument to the executable should be the dataset file to learn from. This dataset should be a comma- or tab-delimited file with columns corresponding to features, one column corresponding to the target, and rows corresponding to samples. the first row should be a header with the names of the features and target. The target must be named as class, target, or label in order to be interpreted correctly. See the datasets in the examples folder for guidance. ENC problem \u00b6 We will run Feat on the energy efficiency dataset from UCI, which is included in examples/d_enc.txt . To run Feat with a population 1000 for 100 generations using a random seed of 42, type ./build/feat examples/d_enc.csv -p 100 -g 100 -r 42 The default verbosity=1, so you will get a printout of summary statistics each generation. The final output should look like Generation 100/100 [//////////////////////////////////////////////////] Min Loss Median Loss Median (Max) Size Time (s) 2.47920e+00 6.27829e+00 27 (37) 27.75276 Representation Pareto Front-------------------------------------- Rank Complexity Loss Representation 1 1 1.65439e+01 [x_4] 1 2 1.25723e+01 [x_0][x_4] 1 3 1.03673e+01 [x_0][x_4][x_6] 1 4 1.01868e+01 [x_0][x_3][x_4][x_6] 1 5 1.00550e+01 [x_0][x_1][x_2][x_4][x_6] 1 6 9.98319e+00 [x_0][x_1][x_2][x_4][x_6][x_7] 1 7 9.78112e+00 [(x_1^2)][x_2][x_4][x_6] 1 8 9.70928e+00 [x_7][(x_1^2)][x_2][x_4][x_6] 1 9 9.68727e+00 [x_7][(x_1^2)][x_2][x_3][x_4][x_6] 1 10 9.33169e+00 [x_1][(x_2*x_0)][x_2][x_4][x_6] 1 11 9.32995e+00 [x_1][(x_2*x_0)][x_2][x_4][x_5][x_6] 1 12 8.84481e+00 [x_2][(x_1^2)][x_2][x_3][x_4][x_6][(x_3+x_0)] 1 14 8.08357e+00 [x_6][(x_2/(x_2^2))][x_4] 1 15 8.08357e+00 [x_6][(x_2/(x_2^2))][x_4][x_4] 1 17 7.95839e+00 [x_6][(x_2/(x_2^2))][x_4][(x_0-x_4)] 1 20 7.87072e+00 [x_6][(x_2/(x_2^2))][x_4][(x_6*x_7)] 1 21 7.55717e+00 [(x_2/(x_2^2))][(x_1+(x_6+x_2))][(x_0-x_4)][x_1] 1 22 7.47840e+00 [x_6][(x_2/(x_2^2))][x_4][log(x_1)] 1 23 4.84868e+00 [(x_2/(x_2^2))][(x_1^2)][x_2][x_3][x_4][x_6][(x_3+x_0)] 1 42 4.25015e+00 [((x_1+x_4)^2)][(x_2/x_1)][(x_6+(x_6+x_2))][(x_1-x_2)][((x_1^2)^2)][(x_0^2)][(x_0*x_2)] 1 45 4.23304e+00 [((x_1+x_4)^2)][(x_2/x_1)][(x_6+(x_6+x_2))][(x_1-x_2)][((x_1^2)^2)][(x_0^2)][(x_0*x_2)][(x_1-x_5)] 1 48 3.78240e+00 [((x_1+x_4)^2)][(x_2/x_1)][(x_6+(x_6+x_2))][(x_1-x_2)][((x_1^2)^2)][(x_0^2)][(x_0*x_2)][(x_4+x_3)][(x_1==x_4)] 1 64 3.02734e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)] 1 67 2.96073e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_4-x_7)] 1 70 2.76775e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)] 1 73 2.75930e+00 [x_1][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)][(x_1-x_2)] 1 74 2.75432e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)][(x_6^2)] 1 78 2.74151e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)][exp(x_4)] 1 80 2.57538e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] 1 115 2.52790e+00 [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_0^2))][(x_6+x_2)][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] 1 117 2.49092e+00 [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_0*(x_0^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] 1 129 2.47920e+00 [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/((x_2^2)^2))][(x_1*(x_0^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] finished best training representation: [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/((x_2^2)^2))][(x_1*(x_0^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] train score: 2.479198 best validation representation: [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)] validation score: 3.596077 final_model score: 3.202949 generating training prediction... predicting with best_ind train score: 3.20295e+00 generating test prediction... predicting with best_ind test score: 4.24600e+00 done! tab-delimited csv files \u00b6 When using tab-delimited csv files as input, specify -sep \\\\t or -sep \"\\t\" at the command line. Feat Cross Validator \u00b6 The cross-validation version of Feat named feat_cv is also built and present in the build/ directory. For cross validation, there are several hyperparameters of Feat that can be tuned: pop_size generations ml max_stall selection survival cross_rate functions max_depth max_dim erc objectives feedback There are 2 ways to set the hyper parameters for feat_cv. The first method is to define a string in cv_main.cc file and pass that to the feat_cv constructor. See cv_main.cc for details. The second method is to create a input file containing group of parameters and pass the filepath using -infile flag. Check featcvinput.txt for a sample input file. The input file contains a string similar to the one in cv_main.cc . The general structure of input file is [{'token1': (val1, val2, val3), 'token2': (val1, val2)}, {'token1': (val1, val2, val3), 'token2': (val1, val2)}]","title":"Command line"},{"location":"examples/ex_command_line/#command-line-example","text":"Feat can be run from the command-line. All of its options are configurable there. After a default build, the feat executable will be in the build directory. From the repo directory, type ./build/feat -h to see options. The first argument to the executable should be the dataset file to learn from. This dataset should be a comma- or tab-delimited file with columns corresponding to features, one column corresponding to the target, and rows corresponding to samples. the first row should be a header with the names of the features and target. The target must be named as class, target, or label in order to be interpreted correctly. See the datasets in the examples folder for guidance.","title":"Command line example"},{"location":"examples/ex_command_line/#enc-problem","text":"We will run Feat on the energy efficiency dataset from UCI, which is included in examples/d_enc.txt . To run Feat with a population 1000 for 100 generations using a random seed of 42, type ./build/feat examples/d_enc.csv -p 100 -g 100 -r 42 The default verbosity=1, so you will get a printout of summary statistics each generation. The final output should look like Generation 100/100 [//////////////////////////////////////////////////] Min Loss Median Loss Median (Max) Size Time (s) 2.47920e+00 6.27829e+00 27 (37) 27.75276 Representation Pareto Front-------------------------------------- Rank Complexity Loss Representation 1 1 1.65439e+01 [x_4] 1 2 1.25723e+01 [x_0][x_4] 1 3 1.03673e+01 [x_0][x_4][x_6] 1 4 1.01868e+01 [x_0][x_3][x_4][x_6] 1 5 1.00550e+01 [x_0][x_1][x_2][x_4][x_6] 1 6 9.98319e+00 [x_0][x_1][x_2][x_4][x_6][x_7] 1 7 9.78112e+00 [(x_1^2)][x_2][x_4][x_6] 1 8 9.70928e+00 [x_7][(x_1^2)][x_2][x_4][x_6] 1 9 9.68727e+00 [x_7][(x_1^2)][x_2][x_3][x_4][x_6] 1 10 9.33169e+00 [x_1][(x_2*x_0)][x_2][x_4][x_6] 1 11 9.32995e+00 [x_1][(x_2*x_0)][x_2][x_4][x_5][x_6] 1 12 8.84481e+00 [x_2][(x_1^2)][x_2][x_3][x_4][x_6][(x_3+x_0)] 1 14 8.08357e+00 [x_6][(x_2/(x_2^2))][x_4] 1 15 8.08357e+00 [x_6][(x_2/(x_2^2))][x_4][x_4] 1 17 7.95839e+00 [x_6][(x_2/(x_2^2))][x_4][(x_0-x_4)] 1 20 7.87072e+00 [x_6][(x_2/(x_2^2))][x_4][(x_6*x_7)] 1 21 7.55717e+00 [(x_2/(x_2^2))][(x_1+(x_6+x_2))][(x_0-x_4)][x_1] 1 22 7.47840e+00 [x_6][(x_2/(x_2^2))][x_4][log(x_1)] 1 23 4.84868e+00 [(x_2/(x_2^2))][(x_1^2)][x_2][x_3][x_4][x_6][(x_3+x_0)] 1 42 4.25015e+00 [((x_1+x_4)^2)][(x_2/x_1)][(x_6+(x_6+x_2))][(x_1-x_2)][((x_1^2)^2)][(x_0^2)][(x_0*x_2)] 1 45 4.23304e+00 [((x_1+x_4)^2)][(x_2/x_1)][(x_6+(x_6+x_2))][(x_1-x_2)][((x_1^2)^2)][(x_0^2)][(x_0*x_2)][(x_1-x_5)] 1 48 3.78240e+00 [((x_1+x_4)^2)][(x_2/x_1)][(x_6+(x_6+x_2))][(x_1-x_2)][((x_1^2)^2)][(x_0^2)][(x_0*x_2)][(x_4+x_3)][(x_1==x_4)] 1 64 3.02734e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)] 1 67 2.96073e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_4-x_7)] 1 70 2.76775e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)] 1 73 2.75930e+00 [x_1][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)][(x_1-x_2)] 1 74 2.75432e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)][(x_6^2)] 1 78 2.74151e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)][(x_6*x_7)][exp(x_4)] 1 80 2.57538e+00 [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] 1 115 2.52790e+00 [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_0^2))][(x_6+x_2)][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] 1 117 2.49092e+00 [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_0*(x_0^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] 1 129 2.47920e+00 [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/((x_2^2)^2))][(x_1*(x_0^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] finished best training representation: [((exp(x_3)^2)^2)][(x_2/x_1)][((x_4^2)/((x_2^2)^2))][(x_1*(x_0^2))][(x_6+(x_1+x_2))][((x_6^2)^2)][((x_1^2)^2)][((x_1+x_4)^2)][(x_6*x_4)][(x_0^2)] train score: 2.479198 best validation representation: [x_3][(x_2/x_1)][((x_4^2)/(x_2^2))][(x_1*(x_1^2))][(x_6+(x_1+x_2))][((x_1^2)^2)][((x_1+x_4)^2)][(x_0^2)] validation score: 3.596077 final_model score: 3.202949 generating training prediction... predicting with best_ind train score: 3.20295e+00 generating test prediction... predicting with best_ind test score: 4.24600e+00 done!","title":"ENC problem"},{"location":"examples/ex_command_line/#tab-delimited-csv-files","text":"When using tab-delimited csv files as input, specify -sep \\\\t or -sep \"\\t\" at the command line.","title":"tab-delimited csv files"},{"location":"examples/ex_command_line/#feat-cross-validator","text":"The cross-validation version of Feat named feat_cv is also built and present in the build/ directory. For cross validation, there are several hyperparameters of Feat that can be tuned: pop_size generations ml max_stall selection survival cross_rate functions max_depth max_dim erc objectives feedback There are 2 ways to set the hyper parameters for feat_cv. The first method is to define a string in cv_main.cc file and pass that to the feat_cv constructor. See cv_main.cc for details. The second method is to create a input file containing group of parameters and pass the filepath using -infile flag. Check featcvinput.txt for a sample input file. The input file contains a string similar to the one in cv_main.cc . The general structure of input file is [{'token1': (val1, val2, val3), 'token2': (val1, val2)}, {'token1': (val1, val2, val3), 'token2': (val1, val2)}]","title":"Feat Cross Validator"},{"location":"guide/basics/","text":"","title":"Basics"},{"location":"guide/configuration/","text":"","title":"Configuring Feat"},{"location":"guide/data/","text":"","title":"Data"}]}